{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-process data\n",
    "\n",
    "* Aggregate into single database\n",
    "\n",
    "* Generate cleaning functions to detect and remove outlier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import helix_funcs\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Below should only be run to combine the indidivual results if needed\n",
    "#helix_funcs.combine_processed_results('./processed/grids1/','./master_grid1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing\n",
    "\n",
    "* Remove unused data \n",
    "\n",
    "* Remove outliers based on sigma values\n",
    "\n",
    "    - Loop over individual variables\n",
    "    - Iscolate individual SWL\n",
    "    - Iscolate individual shape_ids\n",
    "    - find standard deviation and mean\n",
    "    - if any value falls outside of 3 sigma flag/remove it\n",
    "\n",
    "* also may need to seperate tables by variables due to size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.6 s, sys: 2.88 s, total: 22.5 s\n",
      "Wall time: 28.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv('./master_grid1.csv')\n",
    "\n",
    "df = df.drop(['season','is_monthly','month','min','max','std'], 1) # drop un-wanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7234045"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7234045"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prior to dropping bad rows...\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigma_filter(tmp_array, sigma=3, verbose=False):\n",
    "    \"\"\" Given an array of values, return back a list of\n",
    "        booleans that can be used as an index, which\n",
    "        are true when the cells area average fall outside of the \n",
    "        X sigma range of the group mean.\n",
    "        If there arent enough values to determine group stats, a\n",
    "        None is returned instead\n",
    "    \"\"\"\n",
    "    if len(tmp_array) > 3:\n",
    "        shape_std = np.std(tmp_array)\n",
    "        shape_mean = np.mean(tmp_array)\n",
    "        if verbose: print('mean: ',shape_mean,'std: ', shape_std)\n",
    "        lower_range = shape_mean - (sigma * shape_std)\n",
    "        upper_range = shape_mean + (sigma * shape_std)\n",
    "        if verbose: print('valid:', lower_range,'to', upper_range)\n",
    "        truthy_index = [item < lower_range or item > upper_range for item in tmp_array]\n",
    "        return truthy_index\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 17min 55s, sys: 1.12 s, total: 17min 56s\n",
      "Wall time: 17min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Looping over topic, SWL, and shape id, calculate where the rows are outside of a statistical\n",
    "# norm (defined as Â±3sigma around observed mean), and drop those entries from the dataframe.\n",
    "\n",
    "bad_indexs =[]\n",
    "verbose = False\n",
    "\n",
    "for topic in tqdm_notebook(df['impact_tag'].unique()):\n",
    "    tmp_topic = df[df['impact_tag'] == topic]\n",
    "    if verbose: print('Topic:', topic, len(tmp_topic),'items')\n",
    "    for variable in tmp_topic['variable'].unique():\n",
    "        tmp_var = tmp_topic[tmp_topic['variable'] == variable]\n",
    "        if verbose: print('\\tVariable: ',variable, len(tmp_var),'items')\n",
    "        for swl in tmp_var['swl_info'].unique():\n",
    "            tmp_swl = tmp_var[tmp_var['swl_info'] == swl]\n",
    "            if verbose: print('\\t\\tSWL: ',swl,len(tmp_swl),'items')\n",
    "            for shape in tmp_swl['shape_id'].unique():\n",
    "                tmp_shape = tmp_swl[tmp_swl['shape_id'] == shape]\n",
    "                if verbose: print('\\t\\t\\tShape id: ',shape,len(tmp_shape),'items')\n",
    "                tmp_values = tmp_shape['mean'].values\n",
    "                tmp_indexs = sigma_filter(tmp_values, sigma=3, verbose=False)\n",
    "                # Remove bad rows from the large dataframe\n",
    "                if tmp_indexs:\n",
    "                    bad_indexs.append(list(tmp_shape.index[tmp_indexs].values))\n",
    "                    if verbose: \n",
    "                        cnt = 0\n",
    "                        for t in tmp_indexs:\n",
    "                            if t == True:\n",
    "                                cnt += 1\n",
    "                        print('found',cnt,'/',len(tmp_values),'out of bounds')\n",
    "                #break  # break for shapes\n",
    "            #break   # break for swls\n",
    "        #break     # break for variables\n",
    "    #break    # break for topics\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flat_indexs = []\n",
    "\n",
    "for i_list in bad_indexs:\n",
    "    for i in i_list:\n",
    "        flat_indexs.append(i)\n",
    "\n",
    "flat_indexs = sorted(flat_indexs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 14025 from table\n",
      "CPU times: user 1.03 s, sys: 320 ms, total: 1.35 s\n",
      "Wall time: 1.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_size = len(df)\n",
    "\n",
    "df = df.drop(flat_indexs)\n",
    "\n",
    "end_size = len(df)\n",
    "\n",
    "print(\"Dropped\", start_size - end_size,'from table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('./master_1deg_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./master_1deg_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl_only = df[df['impact_tag'] == 'cl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl_only.to_csv('./test_1deg_cl.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Still too large with CL only..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tx', 'pr', 'ts', 'tn'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_only.variable.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tn = cl_only[cl_only['variable'] == 'tn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tn.to_csv('./test_1deg_tn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2927544, 731917)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cl_only), len(tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Save every variable as their own target csv file\n",
    "\n",
    "Due to size constraints, each variable should have its own table, with a fixed name convention of `table_<topic>_<var>.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cl\n",
      "\t tx\n",
      "\t pr\n",
      "\t ts\n",
      "\t tn\n",
      "w\n",
      "\t perc_change_roff\n",
      "\t perc_change_low_roff\n",
      "\t time_perc_change_SPI6\n",
      "\t time_perc_change_SPI48\n",
      "\t time_perc_change_SRI48\n",
      "\t time_perc_change_SRI6\n",
      "eco\n",
      "\t cSoil\n",
      "\t gpp\n",
      "\t evap\n",
      "\t nbp\n",
      "\t cVeg\n"
     ]
    }
   ],
   "source": [
    "for topic in df['impact_tag'].unique():\n",
    "    print(topic)\n",
    "    tmp_topic = df[df['impact_tag'] == topic]\n",
    "    for variable in tmp_topic['variable'].unique():\n",
    "        tmp_var = tmp_topic[tmp_topic['variable'] == variable]\n",
    "        print('\\t',variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "#df = df.drop(tmp_shape.index[tmp_indexs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len(indexes_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len(set(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set(tmp_shape.index[tmp_indexs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
