{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser for UEAs csv-based crop data\n",
    "\n",
    "### notes\n",
    "\n",
    "country, ISO, Model name , variable, mean, SWL, impact-tag (in filename), \n",
    "\n",
    "* complication - I see the variable should be a mix of the model name (cultivar) + the variable in the filename (e.g. irrigation_avoided_perc_change).\n",
    "\n",
    "* To get country name exactly as it is in the other data we should look it up from the shapefile data.\n",
    "\n",
    "Joint country code (SCG) is replaced by\n",
    "The new 3-letter codes are SRB (Serbia) and MNE (Montenegro).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from iso3166 import countries\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identify_netcdf_and_csv_files(path='data'):\n",
    "    \"\"\"Crawl through a specified folder and return a dict of the netcdf d['nc']\n",
    "    and csv d['csv'] files contained within.\n",
    "    Returns something like\n",
    "    {'nc':'data/CNRS_data/cSoil/orchidee-giss-ecearth.SWL_15.eco.cSoil.nc'}\n",
    "    \"\"\"\n",
    "    netcdf_files = []\n",
    "    csv_files = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if isinstance([], type(files)):\n",
    "            for f in files:\n",
    "                if f.split('.')[-1] in ['nc']:\n",
    "                    netcdf_files.append(''.join([root,'/',f]))\n",
    "                elif  f.split('.')[-1] in ['csv']:\n",
    "                    if f not in ['PopAff_SWLs_Country.csv', 'ExpDam_SWLs_Country.csv']:\n",
    "                        csv_files.append(''.join([root,'/',f]))\n",
    "    return {'nc':netcdf_files,'csv':csv_files}\n",
    "\n",
    "\n",
    "def get_metadata_from_UEA_csv(f):\n",
    "    filename_stripped = f[7:]  # <-- this will be the target ./processed/ + filename_stripped\n",
    "    filename_pieces = filename_stripped.split('/')\n",
    "    exploded_filename = filename_pieces[-1].split(\".\")\n",
    "    tmp_model_taxonomy = exploded_filename[0]\n",
    "    # In this case the field that should be model taxonomy has been merged with model name and variable\n",
    "    # I will need to seperate that \n",
    "    model_taxonomy = '-'.join(tmp_model_taxonomy.split('-')[1:])\n",
    "    variable = '_'.join([tmp_model_taxonomy.split('-')[0], exploded_filename[-2]])\n",
    "    #print(tmp_model_taxonomy)\n",
    "\n",
    "    impact_tag = filename_pieces[-1].split(\".\")[2]\n",
    "\n",
    "    tmp_swl = filename_pieces[-1].split(\".\")[1]\n",
    "    if tmp_swl == 'SWL_15':\n",
    "        swl_info = 1.5\n",
    "    elif tmp_swl == 'SWL_2':\n",
    "        swl_info = 2.0\n",
    "    elif tmp_swl == 'SWL_4':\n",
    "        swl_info = 4.0\n",
    "    elif tmp_swl == 'SWL_6':\n",
    "        swl_info = 6.0\n",
    "    else:\n",
    "        raise ValueError(\"Unknown SWL input {}\".format(tmp_swl))\n",
    "\n",
    "    model_short_name = None\n",
    "    season = None\n",
    "    is_seasonal = None\n",
    "    is_monthly = None\n",
    "    month = None\n",
    "    is_multi_model_summary = None\n",
    "    model_long_name = None\n",
    "    institution = None\n",
    "    d = {'swl_info': swl_info,\n",
    "         'model_taxonomy': model_taxonomy,\n",
    "         'impact_tag': impact_tag,\n",
    "         'variable': variable,\n",
    "         'model_short_name':model_short_name,\n",
    "         'is_seasonal': False,\n",
    "         'season': season,\n",
    "         'is_monthly': False,\n",
    "         'month': month,\n",
    "         'is_multi_model_summary': False,\n",
    "         'model_long_name':model_long_name,\n",
    "         'institution': institution\n",
    "        }\n",
    "    return d\n",
    "\n",
    "\n",
    "def process_csv_file(f, s, verbose=False):\n",
    "    keys =['name_0','iso','variable','swl_info',\n",
    "            'count', 'max','min','mean','std','impact_tag','institution',\n",
    "            'model_long_name','model_short_name','model_taxonomy',\n",
    "            'is_multi_model_summary','is_seasonal','season','is_monthly',\n",
    "            'month']\n",
    "    df = pd.read_csv(f)\n",
    "    SCG_value = None\n",
    "    f_level_dic = get_metadata_from_UEA_csv(f)\n",
    "    # We need to do this via the CSV data not the shapefile data as csv data has iso's not present in shapefiles\n",
    "    # which we will need to deal with somehow.\n",
    "    mean_key = df.keys()[-1]\n",
    "    tmp_data = []\n",
    "    for row in df.index:\n",
    "        csv_iso = df['ISO3'][row]\n",
    "        csv_value = df[mean_key][row]\n",
    "        meta_1 = {'iso': csv_iso, 'mean':csv_value, 'count':None, 'min':None, 'max': None, 'std':None}\n",
    "        smask = s['iso'] == meta_1['iso']\n",
    "        if all([len(s[smask]) != 1, csv_iso != 'SCG']):\n",
    "            if verbose: print(csv_iso,' has unexpected size',s[smask])\n",
    "        if csv_iso == 'SCG':\n",
    "            if verbose: print(\"Found Serbia-Montenegro\")\n",
    "            SCG_value = csv_value\n",
    "        else:\n",
    "            # Assume all is well if only one shape matched\n",
    "            meta_2 = {'name_0': s[smask]['name_0'].values[0]}\n",
    "        tmp_d = {**f_level_dic,**meta_1, **meta_2}\n",
    "        tmp_data.append([tmp_d[key] for key in keys])\n",
    "    # Hack to get Serbia (SRB) and Montenegro (MNE) data into the project:\n",
    "    if SCG_value:\n",
    "        if verbose: print(\"Engaging Serbia-Montenegro hack\")\n",
    "        serbia = {**f_level_dic, 'name_0': 'Serbia', 'iso':'SRB', 'mean': SCG_value,\n",
    "                  'count':None, 'min':None, 'max': None, 'std':None}\n",
    "        montenegro = {**f_level_dic, 'name_0': 'Montenegro', 'iso':'MNE', 'mean': SCG_value,\n",
    "                  'count':None, 'min':None, 'max': None, 'std':None}\n",
    "        tmp_data.append([serbia[key] for key in keys])\n",
    "        tmp_data.append([montenegro[key] for key in keys])\n",
    "    \n",
    "    file_target = '/'.join(['./processed/admin0',f[7:]])  #<-- write target\n",
    "    path_check ='/'.join(file_target.split('/')[:-1])\n",
    "    # WRITE EXTRACTED VALUES TO A SPECIFIC SWL CSV FILE IN PROCESSED with matching filename\n",
    "    if not os.path.exists(path_check):\n",
    "        os.makedirs(path_check)\n",
    "    tmp_df = pd.DataFrame(tmp_data, columns = keys)\n",
    "    tmp_df.to_csv(file_target, index=False)\n",
    "    if verbose: print(\"Generated \", file_target)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs = identify_netcdf_and_csv_files('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n, f in enumerate(fs['csv'][0:5]):\n",
    "    print(n, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = gpd.read_file(\"./data/gadm28_adm0_simplified/gadm28_adm0_simplified.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in fs['csv']:\n",
    "    print('working on', f)\n",
    "    process_csv_file(f=f, s=s, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
