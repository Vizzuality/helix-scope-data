{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-process data\n",
    "\n",
    "* Aggregate into single database\n",
    "\n",
    "* Generate cleaning functions to detect and remove outlier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import helix_funcs\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Below should only be run to combine the indidivual results if needed\n",
    "#helix_funcs.combine_processed_results('./processed/grids1/','./master_grid1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing\n",
    "\n",
    "* Remove unused data \n",
    "\n",
    "* Remove outliers based on sigma values\n",
    "\n",
    "    - Loop over individual variables\n",
    "    - Iscolate individual SWL\n",
    "    - Iscolate individual shape_ids\n",
    "    - find standard deviation and mean\n",
    "    - if any value falls outside of 3 sigma flag/remove it\n",
    "\n",
    "* also may need to seperate tables by variables due to size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.read_csv('./master_grid1.csv')\n",
    "\n",
    "df = df.drop(['season','is_monthly','month','min','max','std'], 1) # drop un-wanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prior to dropping bad rows...\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigma_filter(tmp_array, sigma=3):\n",
    "    \"\"\" Given an array of values, return back a list of\n",
    "        booleans that can be used as an index, which\n",
    "        are true when the cells area average fall outside of the \n",
    "        X sigma range of the group mean.\n",
    "        If there arent enough values to determine group stats, a\n",
    "        None is returned instead\n",
    "    \"\"\"\n",
    "    if len(tmp_array) > 3:\n",
    "        shape_std = np.std(tmp_array)\n",
    "        shape_mean = np.mean(tmp_array)\n",
    "        print('mean: ',shape_mean,'std: ', shape_std)\n",
    "        lower_range = shape_mean - (sigma * shape_std)\n",
    "        upper_range = shape_mean + (sigma * shape_std)\n",
    "        print('valid:', lower_range,'to', upper_range)\n",
    "        truthy_index = [item < lower_range or item > upper_range for item in tmp_array]\n",
    "        return truthy_index\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Looping over topic, SWL, and shape id, calculate where the rows are outside of a statistical\n",
    "# norm (defined as Â±3sigma around observed mean), and drop those entries from the dataframe.\n",
    "\n",
    "bad_indexs =[]\n",
    "verbose = False\n",
    "\n",
    "for topic in df['impact_tag'].unique():\n",
    "    tmp_topic = df[df['impact_tag'] == topic]\n",
    "    if verbose: print('Topic:', topic, len(tmp_topic),'items')\n",
    "    for variable in tmp_topic['variable'].unique():\n",
    "        tmp_var = tmp_topic[tmp_topic['variable'] == variable]\n",
    "        if verbose: print('\\tVariable: ',variable, len(tmp_var),'items')\n",
    "        for swl in tmp_var['swl_info'].unique():\n",
    "            tmp_swl = tmp_var[tmp_var['swl_info'] == swl]\n",
    "            if verbose: print('\\t\\tSWL: ',swl,len(tmp_swl),'items')\n",
    "            for shape in tmp_swl['shape_id'].unique():\n",
    "                tmp_shape = tmp_swl[tmp_swl['shape_id'] == shape]\n",
    "                if verbose: print('\\t\\t\\tShape id: ',shape,len(tmp_shape),'items')\n",
    "                tmp_values = tmp_shape['mean'].values\n",
    "                tmp_indexs = sigma_filter(tmp_values, sigma=3)\n",
    "                # Remove bad rows from the large dataframe\n",
    "                if tmp_indexs:\n",
    "                    cnt = 0\n",
    "                    for t in tmp_indexs:\n",
    "                        if t == True:\n",
    "                            cnt += 1\n",
    "                    if verbose: print('found',cnt,'/',len(tmp_values),'out of bounds')\n",
    "                    bad_indexs.append(list(tmp_shape.index[tmp_indexs].values))\n",
    "                #break  # break for shapes\n",
    "            #break   # break for swls\n",
    "        #break     # break for variables\n",
    "    #break    # break for topics\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flat_indexs = []\n",
    "\n",
    "for i_list in bad_indexs:\n",
    "    for i in i_list:\n",
    "        flat_indexs.append(i)\n",
    "\n",
    "flat_indexs = sorted(flat_indexs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "start_size = len(df)\n",
    "\n",
    "df = df.drop(flat_indexs)\n",
    "\n",
    "end_size = len(df)\n",
    "\n",
    "print(\"Dropped\", start_size - end_size,'from table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('./master_1deg_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "#df = df.drop(tmp_shape.index[tmp_indexs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len(indexes_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len(set(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set(tmp_shape.index[tmp_indexs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
